---
title: 'SpeechEQ: Speech Emotion Recognition based on Multi-scale Unified Datasets and Multitask Learning'
authors:
  - Zuheng Kang
  - Junqing Peng
  - Jianzong Wang
  - Jing Xiao
corresponding_author:
    - ''
    - ''
    - 'Corresponding author' 
date: '2022-09-18T00:00:00Z' # TODO
doi: ''


# Publication type.
# Legend: 0 = Uncategorized; 1 = Conference paper; 2 = Journal article;
# 3 = Preprint / Working Paper; 4 = Report; 5 = Book; 6 = Book section;
# 7 = Thesis; 8 = Patent
publication_types: ['1']

# Publication name and optional abbreviated publication name.
publication: In *23rd Annual Conference of the International Speech Communication Association*
publication_short: In *Interspeech2022* (CCF-C)

abstract: Speech emotion recognition (SER) has many challenges, but one of the main challenges is that each framework does not have a unified standard. In this paper, we propose SpeechEQ, a framework for unifying SER tasks based on a multi-scale unified metric. This metric can be trained by Multitask Learning (MTL), which includes two emotion recognition tasks of Emotion States Category (EIS) and Emotion Intensity Scale (EIS), and two auxiliary tasks of phoneme recognition and gender recognition. For this framework, we build a Mandarin SER dataset - SpeechEQ Dataset (SEQD). We conducted experiments on the public CASIA and ESD datasets in Mandarin, which exhibit that our method outperforms baseline methods by a relatively large margin, yielding 8.0% and 6.5% improvement in accuracy respectively. Additional experiments on IEMOCAP with four emotion categories (i.e., angry, happy, sad, and neutral) also show the proposed method achieves a state-of-the-art of both weighted accuracy (WA) of 78.16% and unweighted accuracy (UA) of 77.47%.




tags:
  - Speech
featured: true

links:
- name: "ISCA"
  url: "https://www.isca-speech.org/archive/interspeech_2022/kang22d_interspeech.html"
- name: "arXiv"
  url: "https://arxiv.org/abs/2206.13101"
url_pdf: 'https://www.isca-speech.org/archive/pdfs/interspeech_2022/kang22d_interspeech.pdf'
url_code: ''
url_poster: ''
url_slides: ''

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
image:
  caption: 'Network topology of the SpeechEQ framework'
  focal_point: ''
  preview_only: false


---

{{% callout note %}}
Click the _Cite_ button above to demo the feature to enable visitors to import publication metadata into their reference management software.
{{% /callout %}}

